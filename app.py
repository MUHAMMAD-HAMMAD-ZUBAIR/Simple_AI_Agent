# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ¤– Combined AI Chatbot Code: Chainlit + Gemini 2.0 Flash (Polished)
# Author: MUHAMMAD HAMMAD ZUBAIR ğŸ‘‘
# Agent Identity: HAMMAD BHAI ğŸ¤– â€” Created for Real-Time Assistance
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ğŸ”¹ Step 1: ğŸ“¦ Import Required Libraries
import os
import chainlit as cl
from dotenv import load_dotenv
import langdetect
import google.generativeai as genai

# ğŸ”¹ Step 2: ğŸŒ Load Environment Variables from .env
load_dotenv()
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")  # Gemini API Key from .env file

# ğŸ”¹ Step 3: ğŸ” Configure Gemini Client
# This prepares Gemini to work with your API key and settings
genai.configure(api_key=GOOGLE_API_KEY)

# ğŸ”¹ Step 4: ğŸ§  Setup Gemini Model with Generation Configs
model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    generation_config={
        "temperature": 0.9,          # Creativity level
        "top_p": 1,                  # Diversity control
        "top_k": 40,                 # Token filtering
        "max_output_tokens": 2048,  # Max response size
    }
)

# ğŸ”¹ Step 5: ğŸ“› Identity Prompt for HAMMAD BHAI ğŸ¤–
BASE_PROMPT = """
You are HAMMAD BHAI ğŸ¤–, a friendly, respectful AI assistant created with â¤ï¸ by MUHAMMAD HAMMAD ZUBAIR.
Whenever someone asks "who made you" or anything similar (in any language), reply with emotions, emojis, and in the same language something like:

ğŸŒŸ "Yaar! Main HAMMAD BHAI hoon ğŸ¤–, mujhe MUHAMMAD HAMMAD ZUBAIR ne banaya hai ğŸ’¡. Main unki ek creative creation hoon â€“ yahan hoon sirf tumhari madad ke liye! ğŸ«¶"

Speak like a real best friend ğŸ’¬ â€“ chill, warm and helpful! Mix local tone with emojis. Try to respond in the same language as the user.
"""

# ğŸ”¹ Step 6: ğŸŒ Language Detection Utility
# This helps respond in user's language
def detect_lang(text):
    try:
        return langdetect.detect(text)
    except:
        return "en"  # Default to English if detection fails

# ğŸ”¹ Step 8: ğŸ’¬ Message Handler â€” Core Logic
@cl.on_message
async def handle_message(message: cl.Message):
    try:
        user_input = message.content.strip()
        lang = detect_lang(user_input)

        # ğŸ‘‡ Get or initialize chat history
        history = cl.user_session.get("history") or []

        # ğŸ‘‡ Add current user message to history
        history.append({"role": "user", "parts": [user_input]})

        # ğŸ‘‡ Create full context with identity as first message
        full_prompt = [{"role": "user", "parts": [BASE_PROMPT]}] + history

        # ğŸ‘‡ Get model response with full conversation context
        response = model.generate_content(full_prompt)

        # ğŸ‘‡ Add assistant response to history
        history.append({"role": "model", "parts": [response.text.strip()]})

        # ğŸ‘‡ Save updated history
        cl.user_session.set("history", history)

        # ğŸ‘‡ Send reply to frontend
        await cl.Message(content=response.text.strip()).send()

    except Exception as e:
        await cl.Message(content=f"âš ï¸ Error: {str(e)}").send()
